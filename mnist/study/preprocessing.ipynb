{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e22167d-58bc-4211-aeb5-ff0a5a8b1fed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388a248-3771-45ba-bcc3-0f76630b797c",
   "metadata": {},
   "source": [
    "## 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b947a62-5bba-4dbe-a00d-97ad515428c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna() # 결측치 제거\n",
    "\n",
    "data = data.fillna(titanic.mean()) # 평균값으로 대체\n",
    "\n",
    "data = data.fillna(titanic.median()) #중앙값으로 대체\n",
    "\n",
    "data = data.fillna(-1)  # 예를 들어, -1로 대체\n",
    "\n",
    "data = data.fillna(method='ffill')  # 이전 값으로 대체 (forward fill)\n",
    "\n",
    "data = data.fillna(titanic.mode().iloc[0]) # 최빈값으로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1efc0-d3a2-4184-b8be-8193b2621068",
   "metadata": {},
   "source": [
    "## 이상치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccdf7846-153e-4dd3-9142-aeac4db9036d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[ 7  4  8  5  7  3  7  8  5  4  8  8  3  6  5  2  8  6  2  5  1  6  9  1\n",
      "  3  7  4  9  3  5  3  7  5  9  7  2  4  9  2  9  5  2  4  7  8  3  1  4\n",
      "  2  8 13 11 15 63 13 63 72 27 53 43 83 71 23 57 24 81 87 71 49 89 62 33\n",
      " 35 69 50 38 24 54 74 80 18 10 17 72 20 17 44 44 42 14 50 37 16 82 81 92\n",
      " 91 97 97 98]\n",
      "Identified Outliers:\n",
      "[89, 92, 91, 97, 97, 98]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(42)\n",
    "data = np.concatenate([np.random.randint(1, 10, 50), np.random.randint(10, 90, 45), np.random.randint(91, 100, 5)])\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "\n",
    "# 이상치 식별\n",
    "std_dev = np.std(data)\n",
    "mean = np.mean(data)\n",
    "lower_bound = mean - 2 * std_dev\n",
    "upper_bound = mean + 2 * std_dev\n",
    "outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "\n",
    "print(\"Identified Outliers:\")\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "685456c5-1aab-4bf2-9a8e-4b58d4db31ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Outliers Replaced:\n",
      "[ 7  4  8  5  7  3  7  8  5  4  8  8  3  6  5  2  8  6  2  5  1  6  9  1\n",
      "  3  7  4  9  3  5  3  7  5  9  7  2  4  9  2  9  5  2  4  7  8  3  1  4\n",
      "  2  8 13 11 15 63 13 63 72 27 53 43 83 71 23 57 24 81 87 71 49 28 62 33\n",
      " 35 69 50 38 24 54 74 80 18 10 17 72 20 17 44 44 42 14 50 37 16 82 81 28\n",
      " 28 28 28 28]\n"
     ]
    }
   ],
   "source": [
    "# 이상치 평균값으로 대체\n",
    "data_cleaned = np.where((data < lower_bound) | (data > upper_bound), round(mean), data)\n",
    "\n",
    "print(\"Data with Outliers Replaced:\")\n",
    "print(data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad14c4-c1b6-4a81-b910-b2271ec7e4c0",
   "metadata": {},
   "source": [
    "# 데이터 스케일링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc55f3-cc26-4588-afa5-8db2c4a5846d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MinMaxScaler\n",
    "\n",
    "이 스케일러는 데이터를 0과 1 사이로 변환합니다.  \n",
    "(x-min(x)) / (max(x)-min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680f5e07-deea-4652-8ea4-6853440d0079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Feature1  Feature2  Feature3\n",
      "0  0.374540  0.950714  0.731994\n",
      "1  0.598658  0.156019  0.155995\n",
      "2  0.058084  0.866176  0.601115\n",
      "3  0.708073  0.020584  0.969910\n",
      "4  0.832443  0.212339  0.181825\n",
      "\n",
      "Normalized Data:\n",
      "    Feature1  Feature2  Feature3\n",
      "0  0.408669  1.000000  0.707690\n",
      "1  0.698093  0.145608  0.000000\n",
      "2  0.000000  0.909111  0.546888\n",
      "3  0.839390  0.000000  1.000000\n",
      "4  1.000000  0.206159  0.031736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 예제 데이터 생성\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(5, 3)  # 5행 3열의 랜덤 데이터\n",
    "\n",
    "# 데이터프레임 생성 (예제 데이터를 사용할 때 주로 사용)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data, columns=['Feature1', 'Feature2', 'Feature3'])\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# 정규화된 데이터 출력\n",
    "normalized_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"\\nNormalized Data:\\n\", normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fdb39-ec49-4178-9d74-8480351f7021",
   "metadata": {},
   "source": [
    "### StandardScaler\n",
    "\n",
    "이 스케일러는 데이터를 평균이 0이고 표준편차가 1이 되도록 변환합니다.  \n",
    "(x - mean(x)) / std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43beb82e-afab-41ff-b4cc-7bdf8e856604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Feature1  Feature2  Feature3\n",
      "0  0.374540  0.950714  0.731994\n",
      "1  0.598658  0.156019  0.155995\n",
      "2  0.058084  0.866176  0.601115\n",
      "3  0.708073  0.020584  0.969910\n",
      "4  0.832443  0.212339  0.181825\n",
      "\n",
      "Normalized Data:\n",
      "    Feature1  Feature2  Feature3\n",
      "0 -0.511541  1.314917  0.644253\n",
      "1  0.308415 -0.735840 -1.176364\n",
      "2 -1.669325  1.096761  0.230572\n",
      "3  0.708716 -1.085336  1.396257\n",
      "4  1.163735 -0.590502 -1.094719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# 정규화된 데이터 출력\n",
    "normalized_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"\\nNormalized Data:\\n\", normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026146bf-f1c5-48a5-be22-452f13b882e4",
   "metadata": {},
   "source": [
    "### RobustScaler\n",
    "\n",
    "RobustScaler는 중앙값(median)과 IQR(Interquartile Range)를 사용하여 특성들을 스케일링합니다.  \n",
    "IQR은 데이터의 25번째 백분위수(Q1, 제1사분위수)와 75번째 백분위수(Q3, 제3사분위수) 사이의 범위를 나타냅니다.  \n",
    "RobustScaler는 특성들의 중앙값을 0으로, IQR을 1로 만들어줍니다.  \n",
    "이러한 특성 때문에 이상치(outliers)에 덜 민감한 특성이 있습니다. 이상치가 많은 데이터셋에 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfdfc81d-9c62-4dfb-98ef-5509d7d46ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Feature1  Feature2  Feature3\n",
      "0  0.374540  0.950714  0.731994\n",
      "1  0.598658  0.156019  0.155995\n",
      "2  0.058084  0.866176  0.601115\n",
      "3  0.708073  0.020584  0.969910\n",
      "4  0.832443  0.212339  0.181825\n",
      "\n",
      "Normalized Data:\n",
      "    Feature1  Feature2  Feature3\n",
      "0 -0.671954  1.039734  0.237889\n",
      "1  0.000000 -0.079307 -0.809061\n",
      "2 -1.620756  0.920693  0.000000\n",
      "3  0.328046 -0.270017  0.670330\n",
      "4  0.700934  0.000000 -0.762111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# 정규화된 데이터 출력\n",
    "normalized_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"\\nNormalized Data:\\n\", normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf0c9d-30e4-44b7-808e-07bf794a35aa",
   "metadata": {},
   "source": [
    "### Normalizer\n",
    "\n",
    "Normalizer는 각 특성 벡터를 유클리드 거리가 1이 되도록 변환합니다.  \n",
    "이는 각 데이터 포인트를 벡터로 취급하고, 해당 벡터를 정규화하여 길이를 1로 만드는 작업입니다.  \n",
    "이러한 정규화는 각 데이터 포인트를 단위 길이로 변환하여 다른 관점에서 비교할 때 유용합니다.  \n",
    "예를 들어, 유사도 측정이나 클러스터링 알고리즘에서 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ccbdc91-b2d2-4b0d-90ad-7dc0ded2f90c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " [[1, 2], [3, 4], [5, 6]]\n",
      "\n",
      "Normalized Data:\n",
      " [[0.4472136  0.89442719]\n",
      " [0.6        0.8       ]\n",
      " [0.6401844  0.76822128]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# 예제 데이터 생성\n",
    "data = [[1, 2],\n",
    "     [3, 4],\n",
    "     [5, 6]]\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 정규화된 데이터 출력\n",
    "print(\"Original Data:\\n\", data)\n",
    "print(\"\\nNormalized Data:\\n\", scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32101e02-5957-4e84-86c3-023d6ca7cd4f",
   "metadata": {},
   "source": [
    "# 차원축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38faec1f-0c1f-42b4-8249-5140313dffaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (10, 5)\n",
      "[[0.37454012 0.95071431 0.73199394 0.59865848 0.15601864]\n",
      " [0.15599452 0.05808361 0.86617615 0.60111501 0.70807258]\n",
      " [0.02058449 0.96990985 0.83244264 0.21233911 0.18182497]\n",
      " [0.18340451 0.30424224 0.52475643 0.43194502 0.29122914]\n",
      " [0.61185289 0.13949386 0.29214465 0.36636184 0.45606998]\n",
      " [0.78517596 0.19967378 0.51423444 0.59241457 0.04645041]\n",
      " [0.60754485 0.17052412 0.06505159 0.94888554 0.96563203]\n",
      " [0.80839735 0.30461377 0.09767211 0.68423303 0.44015249]\n",
      " [0.12203823 0.49517691 0.03438852 0.9093204  0.25877998]\n",
      " [0.66252228 0.31171108 0.52006802 0.54671028 0.18485446]]\n",
      "Transformed Data Shape: (10, 2)\n",
      "[[ 0.56141715 -0.16712381]\n",
      " [ 0.01600634  0.61358387]\n",
      " [ 0.88469781  0.08312493]\n",
      " [ 0.17512929  0.14441486]\n",
      " [-0.25376338 -0.04229751]\n",
      " [-0.09108191 -0.36621103]\n",
      " [-0.7391968   0.24596106]\n",
      " [-0.44240949 -0.26632862]\n",
      " [-0.09652537 -0.01912396]\n",
      " [-0.01427363 -0.2259998 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# 예시 데이터 생성\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(10, 5)  # 100개의 샘플, 각 샘플은 5개의 특성으로 구성된 데이터\n",
    "\n",
    "# PCA 모델 생성\n",
    "pca = PCA(n_components=2)  # 2차원으로 축소\n",
    "\n",
    "# PCA 모델을 사용하여 데이터 변환\n",
    "transformed_data = pca.fit_transform(data)\n",
    "\n",
    "print(\"Original Data Shape:\", data.shape)\n",
    "print(data)\n",
    "print(\"Transformed Data Shape:\", transformed_data.shape)\n",
    "print(transformed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
